{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce993d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#web scrape wikipedia for list of presidential candidates with party info and total popular vote\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_United_States_presidential_candidates_by_number_of_votes_received\"\n",
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcfac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f0f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = []\n",
    "year = []\n",
    "party = []\n",
    "popular_votes = []\n",
    "winner = []\n",
    "\n",
    "num_iter = len(soup.select('table:nth-child(3) td'))\n",
    "for i in range(0,num_iter,5):\n",
    "    candidate.append(soup.select('table:nth-child(3) td')[i].get_text().split(',')[1].strip())\n",
    "    year.append(soup.select('table:nth-child(3) td')[i+1].get_text().strip())\n",
    "    party.append(soup.select('table:nth-child(3) td')[i+2].get_text().strip())\n",
    "    popular_votes.append(soup.select('table:nth-child(3) td')[i+3].get_text().split('[')[0])\n",
    "    winner.append(soup.select('table:nth-child(3) td')[i+4].get_text().split('.')[0])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13886852",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_presidential = pd.DataFrame({\"candidate\":candidate, \"year\":year, \"party\":party, \"popular_vote\":popular_votes, \"winner\":winner})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051785ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_presidential['year'] = us_presidential['year'].astype('int64')\n",
    "us_presidential = us_presidential[us_presidential['year'] >= 2006]\n",
    "us_presidential.sort_values(by=['year'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70df243",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_presidential['popular_vote'] = [int(x.replace(',','')) for x in us_presidential['popular_vote']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed87f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_presidential.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_winner(x):\n",
    "    if 'Winner' in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_presidential['winner'] = [name_winner(x) for x in us_presidential['winner']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ppv(x):\n",
    "    yr = us_presidential[us_presidential['year']==us_presidential['year'][x]]\n",
    "    tpv = yr['popular_vote'].sum()\n",
    "    ppv = us_presidential['popular_vote'][x]/tpv\n",
    "    return ppv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_presidential['percent_popular_vote'] = list(map(make_ppv,range(len(us_presidential))))\n",
    "us_presidential.drop('popular_vote', axis=1, inplace=True)\n",
    "us_presidential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names(x):\n",
    "    if x[0]==x[1]:\n",
    "        return x[1:]\n",
    "    else:\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_presidential['candidate'] = list(map(clean_names, us_presidential['candidate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5673d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_presidential['winner'] = us_presidential['winner'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc088e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_presidential.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2592821f",
   "metadata": {},
   "source": [
    "# gubernatorial elections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9177db",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/2020_United_States_gubernatorial_elections\"\n",
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8448aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf046f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mw-content-text > div.mw-parser-output > table:nth-child(30)\n",
    "t1 = soup.select('table:nth-child(30) tbody tr')\n",
    "t1[6].select('th a')[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c1d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "candidates = []\n",
    "\n",
    "for i in range(2,len(t1)):\n",
    "    candidates.append(t1[i].select('td')[4].get_text().strip())\n",
    "    states.append(t1[i].select('th a')[0].get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e678ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_20 = pd.DataFrame({'state':states, 'candidate':candidates})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e71962",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = []\n",
    "for i in range(len(g_20)):\n",
    "    c_list = g_20['candidate'].iloc[i].split('%')\n",
    "    for j in c_list:\n",
    "        if j:\n",
    "            r = {'candidate':j, 'state':g_20['state'][i]}\n",
    "            #print(r)\n",
    "            g_20 = g_20.append(r, ignore_index=True)\n",
    "            drop_list.append(i)\n",
    "g_20.drop(drop_list,axis=0,inplace=True)\n",
    "g_20.reset_index(drop=True, inplace=True)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd3a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_20['winner'] = 0\n",
    "g_20['party'] = 0\n",
    "g_20['percent_popular_vote'] = 0\n",
    "\n",
    "for i in range(len(g_20)):\n",
    "    l = g_20['candidate'][i].split(' ')\n",
    "    if l[0] == 'Y':\n",
    "        g_20['winner'].iloc[i] = 1\n",
    "        l.pop(0)\n",
    "    g_20['percent_popular_vote'][i] = l[-1]\n",
    "    l.pop(-1)\n",
    "    g_20['party'][i] = l[-1][1]\n",
    "    l.pop(-1)\n",
    "    g_20['candidate'][i] = ' '.join(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b15fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_20['year'] = 2020\n",
    "g_20 = g_20[['candidate', 'year', 'state', 'party', 'percent_popular_vote', 'winner']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae7987",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1776e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gubes(year, selector):\n",
    "\n",
    "    url = f\"https://en.wikipedia.org/wiki/{year}_United_States_gubernatorial_elections\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print('response status: ',response.status_code)\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    t1 = soup.select(f'{selector} tbody tr')\n",
    "\n",
    "    states = []\n",
    "    candidates = []\n",
    "\n",
    "    for i in range(2,len(t1)):\n",
    "        candidates.append(t1[i].select('td')[4].get_text().strip())\n",
    "        states.append(t1[i].select('th a')[0].get_text())\n",
    "    \n",
    "    df = pd.DataFrame({'state':states, 'candidate':candidates})\n",
    "    df['year'] = year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee87f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_19 = get_gubes(2019,'table:nth-child(14)')\n",
    "g_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_gubes(df):\n",
    "    drop_list = []\n",
    "    for i in range(len(df)):\n",
    "        c_list = df['candidate'].iloc[i]\n",
    "        c_list = re.sub('\\[\\w+\\]','',c_list)\n",
    "        c_list = re.sub('\\s',' ',c_list)\n",
    "        c_list = c_list.split('%')\n",
    "        for j in c_list:\n",
    "            if j:\n",
    "                r = {'candidate':j, 'state':df['state'][i], 'year':df['year'][i]}\n",
    "                df = df.append(r, ignore_index=True)\n",
    "        drop_list.append(i)\n",
    "    df.drop(drop_list,axis=0,inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df['winner'] = 0\n",
    "    df['party'] = 0\n",
    "    df['percent_popular_vote'] = 0\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        l = df['candidate'][i].split(' ')\n",
    "        if l[0] == 'Y':\n",
    "            df['winner'].iloc[i] = 1\n",
    "            l.pop(0)\n",
    "        df['percent_popular_vote'][i] = l[-1]\n",
    "        l.pop(-1)\n",
    "        df['party'][i] = l[-1][1:-1]\n",
    "        l.pop(-1)\n",
    "        df['candidate'][i] = ' '.join(l)\n",
    "    \n",
    "    df= df[['candidate', 'year', 'state', 'party', 'percent_popular_vote', 'winner', ]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ea56a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_19 = clean_gubes(g_19)\n",
    "g_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df292fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gubes2(year, selector):\n",
    "\n",
    "    url = f\"https://en.wikipedia.org/wiki/{year}_United_States_gubernatorial_elections\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print('response status: ',response.status_code)\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    t1 = soup.select(f'{selector} tbody tr')\n",
    "\n",
    "    states = []\n",
    "    candidates = []\n",
    "\n",
    "    for i in range(1,len(t1)):\n",
    "        candidates.append(t1[i].select('td')[5].get_text().strip())\n",
    "        states.append(t1[i].select('td a')[0].get_text())\n",
    "    \n",
    "    df = pd.DataFrame({'state':states, 'candidate':candidates})\n",
    "    df['year'] = year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6afccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_18 = get_gubes2(2018,'table:nth-child(24)')\n",
    "g_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b72126",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_18 = clean_gubes(g_18)\n",
    "g_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017 does not have info on percent popular vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad283102",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_17 = get_gubes2(2017,'table:nth-child(11)')\n",
    "g_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_17['candidate'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b8adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gubes3(year, selector):\n",
    "\n",
    "    url = f\"https://en.wikipedia.org/wiki/{year}_United_States_gubernatorial_elections\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print('response status: ',response.status_code)\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    t1 = soup.select(f'{selector} tbody tr')\n",
    "\n",
    "    states = []\n",
    "    candidates = []\n",
    "\n",
    "    for i in range(2,len(t1)):\n",
    "        candidates.append(t1[i].select('td')[5].get_text().strip())\n",
    "        states.append(t1[i].select('th a')[0].get_text())\n",
    "    \n",
    "    df = pd.DataFrame({'state':states, 'candidate':candidates})\n",
    "    df['year'] = year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee563d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_16 = get_gubes3(2016,'table:nth-child(13)')\n",
    "g_16 = clean_gubes(g_16)\n",
    "g_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29fd260",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_15 = get_gubes(2015,'table:nth-child(9)')\n",
    "g_15 = clean_gubes(g_15)\n",
    "g_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a24bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_14 = get_gubes(2014,'table:nth-child(18)')\n",
    "g_14 = clean_gubes(g_14)\n",
    "g_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gubes4(year, selector):\n",
    "\n",
    "    url = f\"https://en.wikipedia.org/wiki/{year}_United_States_gubernatorial_elections\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print('response status: ',response.status_code)\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    t1 = soup.select(f'{selector} tbody')\n",
    "\n",
    "    states = []\n",
    "    candidates = []\n",
    "\n",
    "    for i in range(0,len(t1)-1):\n",
    "        states.append(t1[0].select('th a')[i].get_text())\n",
    "        c = t1[0].select('td ul')[i]\n",
    "        c2 = [c.select('li')[x].get_text() for x in range(len(c.select('li')))]\n",
    "        c3 = ''.join(c2)\n",
    "        candidates.append(c3)\n",
    "    \n",
    "    df = pd.DataFrame({'state':states, 'candidate':candidates})\n",
    "    df['year'] = year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d27751",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_13 = get_gubes4(2013,'table.wikitable')\n",
    "g_13 = clean_gubes(g_13)\n",
    "g_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://en.wikipedia.org/wiki/2012_United_States_gubernatorial_elections\"\n",
    "response = requests.get(url)\n",
    "if response.status_code != 200:\n",
    "    print('response status: ',response.status_code)\n",
    "    \n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "t1 = soup.select('table.wikitable tbody')[1]\n",
    "t2 = t1.select('tr')\n",
    "\n",
    "states = []\n",
    "candidates = []\n",
    "\n",
    "for i in range(1,len(t2)):\n",
    "    states.append(t2[i].select('th a')[0].get_text())\n",
    "    c = t2[i].select('td ul li')\n",
    "    c2 = [c[x].get_text() for x in range(len(c))]\n",
    "    c3 = ''.join(c2)\n",
    "    candidates.append(c3)\n",
    "\n",
    "g_12 = pd.DataFrame({'state':states, 'candidate':candidates})\n",
    "g_12['year'] = 2012\n",
    "g_12 = clean_gubes(g_12)\n",
    "g_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb701753",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://en.wikipedia.org/wiki/2011_United_States_gubernatorial_elections\"\n",
    "response = requests.get(url)\n",
    "if response.status_code != 200:\n",
    "    print('response status: ',response.status_code)\n",
    "    \n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "t1 = soup.select('table.wikitable tbody')[1]\n",
    "t2 = t1.select('tr')\n",
    "\n",
    "states = []\n",
    "candidates = []\n",
    "\n",
    "for i in range(1,len(t2)):\n",
    "    states.append(t2[i].select('th a')[0].get_text())\n",
    "    c = t2[i].select('td ul li')\n",
    "    c2 = [c[x].get_text() for x in range(len(c))]\n",
    "    c3 = ''.join(c2)\n",
    "    candidates.append(c3)\n",
    "\n",
    "g_11 = pd.DataFrame({'state':states, 'candidate':candidates})\n",
    "g_11['year'] = 2011\n",
    "g_11 = clean_gubes(g_11)\n",
    "g_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b969007",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://en.wikipedia.org/wiki/2010_United_States_gubernatorial_elections\"\n",
    "response = requests.get(url)\n",
    "if response.status_code != 200:\n",
    "    print('response status: ',response.status_code)\n",
    "    \n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "t1 = soup.select('table.wikitable tbody')[1]\n",
    "t2 = t1.select('tr')\n",
    "\n",
    "states = []\n",
    "candidates = []\n",
    "\n",
    "for i in range(1,len(t2)):\n",
    "    states.append(t2[i].select('th a')[0].get_text())\n",
    "    c = t2[i].select('td ul li')\n",
    "    c2 = [c[x].get_text() for x in range(len(c))]\n",
    "    c3 = ''.join(c2)\n",
    "    candidates.append(c3)\n",
    "\n",
    "g_10 = pd.DataFrame({'state':states, 'candidate':candidates})\n",
    "g_10['year'] = 2010\n",
    "g_10 = clean_gubes(g_10)\n",
    "g_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c5bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://en.wikipedia.org/wiki/2009_United_States_gubernatorial_elections\"\n",
    "response = requests.get(url)\n",
    "if response.status_code != 200:\n",
    "    print('response status: ',response.status_code)\n",
    "    \n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "t1 = soup.select('table.wikitable tbody')[1]\n",
    "t2 = t1.select('tr')\n",
    "\n",
    "states = []\n",
    "candidates = []\n",
    "\n",
    "for i in range(1,len(t2)):\n",
    "    states.append(t2[i].select('th a')[0].get_text())\n",
    "    c = t2[i].select('td ul li')\n",
    "    c2 = [c[x].get_text() for x in range(len(c))]\n",
    "    c3 = ''.join(c2)\n",
    "    candidates.append(c3)\n",
    "\n",
    "g_09 = pd.DataFrame({'state':states, 'candidate':candidates})\n",
    "g_09['year'] = 2009\n",
    "g_09 = clean_gubes(g_09)\n",
    "g_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add91bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://en.wikipedia.org/wiki/2008_United_States_gubernatorial_elections\"\n",
    "response = requests.get(url)\n",
    "if response.status_code != 200:\n",
    "    print('response status: ',response.status_code)\n",
    "    \n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "t1 = soup.select('table.wikitable tbody')[0]\n",
    "t2 = t1.select('tr')\n",
    "\n",
    "states = []\n",
    "candidates = []\n",
    "\n",
    "for i in range(1,len(t2)):\n",
    "    states.append(t2[i].select('th a')[0].get_text())\n",
    "    c = t2[i].select('td ul li')\n",
    "    c2 = [c[x].get_text() for x in range(len(c))]\n",
    "    c3 = ''.join(c2)\n",
    "    candidates.append(c3)\n",
    "\n",
    "g_08 = pd.DataFrame({'state':states, 'candidate':candidates})\n",
    "g_08['year'] = 2008\n",
    "g_08 = clean_gubes(g_08)\n",
    "g_08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59c158",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://en.wikipedia.org/wiki/2007_United_States_gubernatorial_elections\"\n",
    "response = requests.get(url)\n",
    "if response.status_code != 200:\n",
    "    print('response status: ',response.status_code)\n",
    "    \n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "t1 = soup.select('table.wikitable tbody')[0]\n",
    "t2 = t1.select('tr')\n",
    "\n",
    "states = []\n",
    "candidates = []\n",
    "\n",
    "for i in range(1,len(t2)):\n",
    "    states.append(t2[i].select('th a')[0].get_text())\n",
    "    c = t2[i].select('td ul li')\n",
    "    c2 = [c[x].get_text() for x in range(len(c))]\n",
    "    c3 = ''.join(c2)\n",
    "    candidates.append(c3)\n",
    "\n",
    "g_07 = pd.DataFrame({'state':states, 'candidate':candidates})\n",
    "g_07['year'] = 2007\n",
    "g_07 = clean_gubes(g_07)\n",
    "g_07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9118c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://en.wikipedia.org/wiki/2006_United_States_gubernatorial_elections\"\n",
    "response = requests.get(url)\n",
    "if response.status_code != 200:\n",
    "    print('response status: ',response.status_code)\n",
    "    \n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "t1 = soup.select('table.wikitable tbody')[1]\n",
    "t2 = t1.select('tr')\n",
    "\n",
    "states = []\n",
    "candidates = []\n",
    "\n",
    "for i in range(1,len(t2)):\n",
    "    states.append(t2[i].select('th a')[0].get_text())\n",
    "    c = t2[i].select('td ul li')\n",
    "    c2 = [c[x].get_text() for x in range(len(c))]\n",
    "    c3 = ''.join(c2)\n",
    "    candidates.append(c3)\n",
    "\n",
    "g_06 = pd.DataFrame({'state':states, 'candidate':candidates})\n",
    "g_06['year'] = 2006\n",
    "g_06 = clean_gubes(g_06)\n",
    "g_06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af399574",
   "metadata": {},
   "outputs": [],
   "source": [
    "gub = pd.concat([g_20,g_19,g_18,g_16,g_15,g_14,g_13,g_12,g_11,g_10,g_09,g_08,g_07,g_06], axis=0)\n",
    "gub = gub.reset_index(drop=True)\n",
    "gub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b12706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names2(x):\n",
    "    if len(re.findall('\\(', x)) != 0:\n",
    "        a = x.split('(')[0]   \n",
    "        return a.strip() \n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gub['candidate'] = list(map(clean_names2,gub['candidate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79acf02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gub.drop([65], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "gub = gub.reset_index(drop=True)\n",
    "gub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b5f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_presidential.to_csv('pres.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fac4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "gub.to_csv('gub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
