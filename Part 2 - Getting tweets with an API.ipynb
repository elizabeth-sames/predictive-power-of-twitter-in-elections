{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b287db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install git+https://github.com/JustAnotherArchivist/snscrape.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d984c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb88a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pres = pd.read_csv('pres.csv')\n",
    "pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20588cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_phrases = {}\n",
    "for c in pres['candidate']:\n",
    "    phrases = [c, c.split(' ')]\n",
    "    search_phrases[c] = phrases\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(name, year):\n",
    "    tweets = []\n",
    "    for i,t in enumerate(sntwitter.TwitterSearchScraper(f'{name} since:{year}-10-01 until:{year}-10-31').get_items()):\n",
    "        if i>10000:\n",
    "            break\n",
    "        tweets.append([t.date, t.content])\n",
    "    df = pd.DataFrame(tweets, columns=['date', 'tweet'])\n",
    "    df['candidate'] = name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c3935",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = get_tweets(pres['candidate'][0],pres['year'][0])\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d033cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('pres_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94455d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(pres)):\n",
    "    name = pres['candidate'][i]\n",
    "    year = pres['year'][i]\n",
    "    df = get_tweets(name, year)\n",
    "    tweets = pd.concat([tweets, df], axis=0)\n",
    "    tweets.to_csv('pres_tweets.csv')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dfe28e",
   "metadata": {},
   "source": [
    "# gubenatorial candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f3d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gub = pd.read_csv('gub.csv', index_col=0)\n",
    "gub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58133ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dictionary of candidates with state\n",
    "state_dict = {gub['candidate'][i]: gub['state'][i] for i in range(len(gub))}\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in gub['candidate']:\n",
    "    if len(x.split()) <2:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00844e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gub.iloc[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f5fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_phrases = {}\n",
    "for i in range(len(gub)):\n",
    "    c= gub['candidate'][i]\n",
    "    if not c in search_phrases:\n",
    "        l = c.split()[1]\n",
    "        s = gub['state'][i]\n",
    "        phrases = [f'governor {l}', f'{l} {s}', f'{s} {l}']\n",
    "        search_phrases[c] = phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a58c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets2(name, year):\n",
    "    tweets = []\n",
    "    for phrase in search_phrases[name]:\n",
    "        for i,t in enumerate(sntwitter.TwitterSearchScraper(f'{phrase} since:{year}-10-01 until:{year}-10-31').get_items()):\n",
    "            if i>10000:\n",
    "                break\n",
    "            tweets.append([t.date, t.content])\n",
    "    df = pd.DataFrame(tweets, columns=['date', 'tweet'])\n",
    "    df.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "    df['candidate'] = name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f2600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing on first candiate\n",
    "g_tweets = get_tweets(gub['candidate'][0],gub['year'][0])\n",
    "g_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83572a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tweets.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "g_tweets = g_tweets.reset_index(drop=True)\n",
    "g_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b3ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tweets\n",
    "for i in range(1,len(gub)):\n",
    "    name = gub['candidate'][i]\n",
    "    year = gub['year'][i]\n",
    "    df = get_tweets2(name, year)\n",
    "    g_tweets = pd.concat([g_tweets, df], axis=0)\n",
    "    g_tweets.to_csv('gub_tweets.csv')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
